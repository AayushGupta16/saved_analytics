Python Code Catalog
Generated on: 2024-12-09 06:38:14
================================================================================

File: ./count.py
Lines of code: 81
--------------------------------------------------------------------------------

import os
import datetime

def get_python_files(directory="."):
    """
    Gets a list of all Python files in the directory and its subdirectories,
    excluding virtual environment directories.
    Returns a list of file paths.
    """
    python_files = []
    
    # Common virtual environment directory names to exclude
    venv_dirs = {'venv', 'env', '.env', '.venv', 'virtualenv', '.pytest_cache', '__pycache__'}
    
    for root, dirs, files in os.walk(directory):
        # Remove venv directories from dirs list to prevent walking into them
        dirs[:] = [d for d in dirs if d not in venv_dirs]
        
        for file in files:
            if file.endswith('.py'):
                python_files.append(os.path.join(root, file))
    
    return sorted(python_files)  # Sort for consistent output

def create_python_catalog(output_file="python_code_catalog.txt"):
    """
    Creates a text file containing all Python code from the project with file indicators.
    """
    python_files = get_python_files()
    
    if not python_files:
        print("No Python files found in the current directory and its subdirectories.")
        return
    
    try:
        with open(output_file, 'w', encoding='utf-8') as catalog:
            # Write header
            catalog.write("Python Code Catalog\n")
            catalog.write(f"Generated on: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            catalog.write("=" * 80 + "\n\n")
            
            total_files = 0
            total_lines = 0
            
            for file_path in python_files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        lines = content.count('\n') + 1
                        
                        # Write file header
                        catalog.write(f"File: {file_path}\n")
                        catalog.write(f"Lines of code: {lines}\n")
                        catalog.write("-" * 80 + "\n\n")
                        
                        # Write file content
                        catalog.write(content)
                        
                        # Add spacing between files
                        catalog.write("\n\n" + "=" * 80 + "\n\n")
                        
                        total_files += 1
                        total_lines += lines
                        
                except Exception as e:
                    print(f"Error reading {file_path}: {str(e)}")
            
            # Write summary at the end
            catalog.write(f"\nSummary:\n")
            catalog.write(f"Total Python files processed: {total_files}\n")
            catalog.write(f"Total lines of Python code: {total_lines}\n")
            
        print(f"Python code catalog has been created: {output_file}")
        print(f"Total Python files processed: {total_files}")
        print(f"Total lines of Python code: {total_lines}")
        
    except Exception as e:
        print(f"Error creating catalog file: {str(e)}")

if __name__ == "__main__":
    create_python_catalog()

================================================================================

File: ./metrics/avg_streams_per_user.py
Lines of code: 28
--------------------------------------------------------------------------------

import streamlit as st
import pandas as pd

def display_avg_streams_per_user(streams_df):
    """
    Displays a simple average streams per user per week metric, no exclusion.
    Just groups by week and calculates average streams per user.
    """
    if streams_df.empty:
        st.write("No data for Average Streams per User")
        return

    # Ensure datetime
    if not pd.api.types.is_datetime64_any_dtype(streams_df['created_at']):
        streams_df['created_at'] = pd.to_datetime(streams_df['created_at'], utc=True)

    # Group by week (ISO week), compute average
    # We'll define a week_start as Monday-based just for demonstration
    streams_df['week_start'] = streams_df['created_at'] - pd.to_timedelta(streams_df['created_at'].dt.weekday, unit='D')

    weekly_streams = streams_df.groupby(['week_start', 'user_id']).size().reset_index(name='streams')
    avg_per_week = weekly_streams.groupby('week_start')['streams'].mean().reset_index(name='avg_streams')

    st.write("Data for Avg Streams per User:")
    st.dataframe(avg_per_week)  # Debug
    st.write("Average Streams per User (Weekly):")
    st.line_chart(data=avg_per_week, x='week_start', y='avg_streams')


================================================================================

File: ./metrics/monthly_active_users.py
Lines of code: 24
--------------------------------------------------------------------------------

import streamlit as st
import pandas as pd

def display_monthly_active_users(streams_df):
    """
    Displays Monthly Active Users (MAU). Counts unique user_ids per month.
    No exclusion of current month.
    """
    if streams_df.empty:
        st.write("No data for Monthly Active Users")
        return
    
    if not pd.api.types.is_datetime64_any_dtype(streams_df['created_at']):
        streams_df['created_at'] = pd.to_datetime(streams_df['created_at'], utc=True)
    
    streams_df['year_month'] = streams_df['created_at'].dt.to_period('M')
    mau = streams_df.groupby('year_month')['user_id'].nunique().reset_index()
    mau['year_month'] = mau['year_month'].dt.to_timestamp()

    st.write("Data for MAU:")
    st.dataframe(mau)  # Debug
    st.write("Monthly Active Users:")
    st.line_chart(data=mau, x='year_month', y='user_id')


================================================================================

File: ./metrics/monthly_retention.py
Lines of code: 23
--------------------------------------------------------------------------------

import streamlit as st
import pandas as pd

def display_monthly_retention(streams_df):
    """
    Simplified: Just show monthly unique users again (no real retention).
    """
    if streams_df.empty:
        st.write("No data for Monthly Retention (simplified)")
        return
    
    if not pd.api.types.is_datetime64_any_dtype(streams_df['created_at']):
        streams_df['created_at'] = pd.to_datetime(streams_df['created_at'], utc=True)
    
    streams_df['year_month'] = streams_df['created_at'].dt.to_period('M')
    monthly_users = streams_df.groupby('year_month')['user_id'].nunique().reset_index()
    monthly_users['year_month'] = monthly_users['year_month'].dt.to_timestamp()

    st.write("Data for Monthly Retention (simplified):")
    st.dataframe(monthly_users)  # Debug
    st.write("Monthly User Counts (simplified retention):")
    st.line_chart(data=monthly_users, x='year_month', y='user_id')


================================================================================

File: ./metrics/new_user_signups.py
Lines of code: 23
--------------------------------------------------------------------------------

import streamlit as st
import pandas as pd

def display_new_user_signups(users_df):
    """
    Displays New User Signups per week.
    No exclusion of current week, just all data.
    """
    if users_df.empty:
        st.write("No user data for Signups")
        return
    
    if not pd.api.types.is_datetime64_any_dtype(users_df['created_at']):
        users_df['created_at'] = pd.to_datetime(users_df['created_at'], utc=True)
    
    users_df['week_start'] = users_df['created_at'] - pd.to_timedelta(users_df['created_at'].dt.weekday, unit='D')
    weekly_signups = users_df.groupby('week_start').size().reset_index(name='new_users')

    st.write("Data for Weekly Signups:")
    st.dataframe(weekly_signups)  # Debug
    st.write("New User Signups (Weekly):")
    st.line_chart(data=weekly_signups, x='week_start', y='new_users')


================================================================================

File: ./metrics/weekly_intervals.py
Lines of code: 41
--------------------------------------------------------------------------------

import streamlit as st
import pandas as pd

def display_weekly_streams(streams_df):
    """
    Weekly Stream Counts with no exclusions.
    """
    if streams_df.empty:
        st.write("No data for Weekly Streams")
        return
    
    if not pd.api.types.is_datetime64_any_dtype(streams_df['created_at']):
        streams_df['created_at'] = pd.to_datetime(streams_df['created_at'], utc=True)
    
    streams_df['week_start'] = streams_df['created_at'] - pd.to_timedelta(streams_df['created_at'].dt.weekday, unit='D')
    weekly_counts = streams_df.groupby('week_start').size().reset_index(name='streams')

    st.write("Data for Weekly Streams:")
    st.dataframe(weekly_counts)  # Debug
    st.write("Weekly Stream Count:")
    st.line_chart(data=weekly_counts, x='week_start', y='streams')

def display_weekly_active_users(streams_df):
    """
    Weekly Active Users with no exclusions.
    """
    if streams_df.empty:
        st.write("No data for Weekly Active Users")
        return
    
    if not pd.api.types.is_datetime64_any_dtype(streams_df['created_at']):
        streams_df['created_at'] = pd.to_datetime(streams_df['created_at'], utc=True)
    
    streams_df['week_start'] = streams_df['created_at'] - pd.to_timedelta(streams_df['created_at'].dt.weekday, unit='D')
    weekly_active = streams_df.groupby(['week_start'])['user_id'].nunique().reset_index(name='active_users')

    st.write("Data for Weekly Active Users:")
    st.dataframe(weekly_active)  # Debug
    st.write("Weekly Active Users:")
    st.line_chart(data=weekly_active, x='week_start', y='active_users')


================================================================================

File: ./retool.py
Lines of code: 194
--------------------------------------------------------------------------------

import streamlit as st
from supabase import create_client
import pandas as pd
import numpy as np
from dotenv import load_dotenv
from datetime import datetime, timezone

# Import metric components
from metrics.avg_streams_per_user import display_avg_streams_per_user
from metrics.monthly_active_users import display_monthly_active_users
from metrics.monthly_retention import display_monthly_retention
from metrics.new_user_signups import display_new_user_signups
from metrics.weekly_intervals import display_weekly_streams, display_weekly_active_users

# Load environment variables
load_dotenv()


def display_summary_metrics(streams: pd.DataFrame, users: pd.DataFrame) -> None:
    """
    Display the summary metrics section with improved layout and calculations
    """
    st.header('Summary Metrics', divider='blue')
    
    # Create two rows of metrics for better spacing
    row1_cols = st.columns([1, 1])
    row2_cols = st.columns([1, 1])
    
    # 1. Average Streams per Week per User
    with row1_cols[0]:
        if not streams.empty:
            # Calculate using complete weeks only
            start_date = pd.Timestamp('2024-09-29', tz='UTC')
            df = streams.copy()
            df['week_number'] = ((df['created_at'] - start_date) // pd.Timedelta(weeks=1)) + 1
            df['week_start'] = start_date + (df['week_number'] - 1) * pd.Timedelta(weeks=1)
            
            # Get complete weeks only (exclude current week)
            today = pd.Timestamp.now(tz='UTC')
            complete_weeks_data = df[df['week_start'] < today - pd.Timedelta(days=today.weekday())]
            
            if not complete_weeks_data.empty:
                weekly_streams = complete_weeks_data.groupby(['week_start', 'user_id']).size().reset_index(name='streams')
                avg_streams = weekly_streams.groupby('week_start')['streams'].mean().mean()
                
                st.metric(
                    "Average Weekly Streams/User",
                    f"{avg_streams:.1f}",
                    help="Average number of streams per user per week (excluding current week)"
                )
            else:
                st.metric("Average Weekly Streams/User", "0.0")
        else:
            st.metric("Average Weekly Streams/User", "No data")

    # 2. Monthly Active Users (MAU)
    with row1_cols[1]:
        if not streams.empty:
            current_date = pd.Timestamp.now(tz='UTC')
            thirty_days_ago = current_date - pd.Timedelta(days=30)
            active_users = len(streams[streams['created_at'] >= thirty_days_ago]['user_id'].unique())
            
            st.metric(
                "Monthly Active Users",
                f"{active_users:,}",
                help="Unique users who streamed in the last 30 days"
            )
        else:
            st.metric("Monthly Active Users", "No data")

    # 3. Total Users
    with row2_cols[0]:
        if not users.empty:
            total_users = len(users)
            # Calculate user growth
            last_month = pd.Timestamp.now(tz='UTC') - pd.Timedelta(days=30)
            prev_total = len(users[users['created_at'] < last_month])
            growth = ((total_users - prev_total) / prev_total * 100) if prev_total > 0 else 0
            
            st.metric(
                "Total Users",
                f"{total_users:,}",
                f"{growth:+.1f}% in 30 days",
                help="Total number of registered users"
            )
        else:
            st.metric("Total Users", "No data")

    # 4. Premium Users
    with row2_cols[1]:
        if not users.empty:
            premium_users = users[users['is_paying'] == True].shape[0]
            total_users = len(users)
            premium_percentage = (premium_users / total_users * 100) if total_users > 0 else 0
            
            st.metric(
                "Premium Users",
                f"{premium_users:,}",
                f"{premium_percentage:.1f}% of total",
                help="Number of users with premium subscriptions"
            )
        else:
            st.metric("Premium Users", "No data")

def create_analytics_dashboard():
    """
    Create and display the main analytics dashboard with all metrics and visualizations
    """
    try:
        # Initialize Supabase client
        supabase_url = st.secrets["env"]["SUPABASE_URL"]
        supabase_key = st.secrets["env"]["SUPABASE_KEY"]
        supabase = create_client(supabase_url, supabase_key)

        # List of developer user IDs to exclude
        developer_ids = st.secrets["env"]["DEVELOPER_IDS"].split(',')

        # Set page config
        st.set_page_config(
            page_title="Platform Analytics",
            page_icon="📊",
            layout="wide",
            initial_sidebar_state="expanded"
        )

        # Fetch data from all tables
        with st.spinner('Fetching data...'):
            streams = pd.DataFrame(supabase.from_('Streams').select('*').execute().data)
            highlights = pd.DataFrame(supabase.from_('Highlights').select('*').execute().data)
            users = pd.DataFrame(supabase.from_('Users').select('*').execute().data)

            # Filter out developer data
            streams = streams[~streams['user_id'].isin(developer_ids)]
            highlights = highlights[~highlights['user_id'].isin(developer_ids)]
            users = users[~users['user_id'].isin(developer_ids)]

        # Convert timestamps to datetime with UTC
        if not streams.empty:
            streams['created_at'] = pd.to_datetime(streams['created_at'], utc=True)
        if not users.empty:
            users['created_at'] = pd.to_datetime(users['created_at'], utc=True)

        # Main dashboard title with styling
        st.title('📊 Platform Analytics Dashboard')
        st.caption('Data excludes developer activity')

        # Add data freshness indicator
        last_update = pd.Timestamp.now(tz='UTC')
        st.sidebar.info(f"Data last updated: {last_update.strftime('%Y-%m-%d %H:%M:%S')} UTC")

        # Display summary metrics
        display_summary_metrics(streams, users)

        st.caption("📊 Dotted lines and star markers (⭐) indicate projected data for the current period")


        # Create tabs for different metric categories
        tabs = st.tabs(["User Activity", "Retention", "Growth"])

        with tabs[0]:
            st.header("User Activity Metrics")
            
            st.subheader("Weekly Metrics")
            display_avg_streams_per_user(streams)
            display_weekly_streams(streams)
            display_weekly_active_users(streams)

        with tabs[1]:
            st.header("Retention Metrics")
            # Display retention metrics
            display_monthly_retention(streams)

        with tabs[2]:
            st.header("Growth Metrics")
            # Display growth metrics
            display_new_user_signups(users)
            
            # Display highlights metrics if available
            if not highlights.empty:
                st.subheader("Highlights Activity")
                # Add your highlights metrics here

        # Add footer with data disclaimer
        st.markdown("---")
        st.caption("Note: All metrics are calculated based on UTC timezone")

    except Exception as e:
        st.error(f"An error occurred: {str(e)}")
        st.error("Please check your database connection and try again.")
        # Log the full error for debugging
        st.exception(e)

if __name__ == "__main__":
    create_analytics_dashboard()

================================================================================


Summary:
Total Python files processed: 7
Total lines of Python code: 414
